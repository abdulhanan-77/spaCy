{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Using RegEx with spaCy\n"
      ],
      "metadata": {
        "id": "iG3mMGGc6gcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1. Key Concepts in this Notebook¶\n",
        "1. What is RegEx (Regular Expressions)?\n",
        "\n",
        "2. The Strengths of RegEx\n",
        "\n",
        "3. The Weaknesses of RegEx\n",
        "\n",
        "4. How to use RegEx in Python\n",
        "\n",
        "5. How to use RegEx in spaCy"
      ],
      "metadata": {
        "id": "FX0NaCRz6lB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2. What is Regular Expressions (RegEx)\n",
        "\n",
        "Regular Expressions, or RegEx for short, is a way of achieving complex string matching based on simple or complex patterns. It can be used to perform finding and retrieving patterns or replacing matching patterns in a string with some other pattern."
      ],
      "metadata": {
        "id": "tacsYpJeDQYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.3. The Strengths of RegEx\n",
        "\n",
        "There are several strengths to RegEx.\n",
        "\n",
        "* Due to its complex syntax, it can allow for programmers to write robust rules in short spaces.\n",
        "\n",
        "* It can allow the researcher to find all types of variance in strings\n",
        "\n",
        "* It can perform remarkably quickly when compared to other methods.\n",
        "\n",
        "* It is universally supported"
      ],
      "metadata": {
        "id": "khneovD2Dk7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.4. The Weaknesses of RegEx\n",
        "\n",
        "Despite these strengths, there are a few weaknesses to RegEx.\n",
        "\n",
        "1. Its syntax is quite difficult for beginners. (I still find myself looking up how to do certain things).\n",
        "\n",
        "2. It order to work well, it requires a domain-expert to work alongside the programmer to think of all ways a pattern may vary in texts."
      ],
      "metadata": {
        "id": "5Uwp0tqTDxxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.5. How to Use RegEx in Python"
      ],
      "metadata": {
        "id": "Ph6Y7yRxD5NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "l_N3oX35FTKE"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r\"((\\d){1,2} (January|February|March|April|May|June|July|August|September|October|November|December))\"\n",
        "\n",
        "text = \"This is a date 2 February. Another date would be 14 August.\"\n",
        "matches = re.findall(pattern, text)\n",
        "print (matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUMdYNekFZen",
        "outputId": "d7c3b26f-888b-4a8e-85ea-aed1d8f601e8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('2 February', '2', 'February'), ('14 August', '4', 'August')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this bit of code, we see a real-life RegEx formula at work. While this looks quite complex, its syntax is fairly straight forward. Let’s break it down. The first ( tells RegEx that I’m looking for something within the ending ). In other words, I’m looking for a pattern that’s going to match the whole pattern, not just components.\n",
        "\n",
        "Next, we state (\\d){1,2}. This means that we are looking for any digit (0-9) that occurs either once or twice ({1,2}).\n",
        "\n",
        "Next, we have a space to indicate the space in the string that we would expect with a date.\n",
        "\n",
        "Next, we have (January|February|March|April|May|June|July|August|September|October|November|December) – this indicates another component of the pattern (because it is parentheses). The | indicates the same concept as “or” in English, so either January, or February, or March, etc.\n",
        "\n",
        "When we bring it together, this pattern will match anything that functions as a set of one or two numbers followed by a month. What happens when we try and do this with a date that is formed the opposite way?"
      ],
      "metadata": {
        "id": "YBbd5N-bF67n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a date February 2. Another date would be 14 August.\"\n",
        "matches = re.findall(pattern, text)\n",
        "print (matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY7be6hXF9zS",
        "outputId": "e2f2d78f-6d4b-4218-ba9a-f62df993926a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('14 August', '4', 'August')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It fails. But this is no fault of RegEx. Our pattern cannot accommodate that variation. Nevertheless, we can account for it by adding it as a possible variation. Possible variations are accounted for with a *"
      ],
      "metadata": {
        "id": "pI57m-GrGCU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r\"(((\\d){1,2}( (January|February|March|April|May|June|July|August|September|October|November|December)))|(((January|February|March|April|May|June|July|August|September|October|November|December) )(\\d){1,2}))\"\n",
        "\n",
        "text = \"This is a date February 2. Another date would be 14 August.\"\n",
        "matches = re.findall(pattern, text)\n",
        "print (matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRn4tNXqGI5w",
        "outputId": "093f66a2-29b6-411e-8a78-fffd1d21363f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('February 2', '', '', '', '', 'February 2', 'February ', 'February', '2'), ('14 August', '14 August', '4', ' August', 'August', '', '', '', '')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are more concise ways to write the same RegEx formula. I have opted here to be more verbose to make it a bit easier to read. You can see that we’ve allowed for two main options for our pattern matcher.\n",
        "\n",
        "Notice, however, that we have a lot of superfluous information for each match. These are the components of each match. There are several ways we can remove them. One way is to use the command finditer, rather than findall in RegEx."
      ],
      "metadata": {
        "id": "OsvUrqi9G7Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a date February 2. Another date would be 14 August.\"\n",
        "iter_matches = re.finditer(pattern, text)\n",
        "print (iter_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIsrlVwOG-Kb",
        "outputId": "cc35c486-c4a4-41a2-cda0-0fde96599b80"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<callable_iterator object at 0x7e5c7b447460>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a date February 2. Another date would be 14 August.\"\n",
        "iter_matches = re.finditer(pattern, text)\n",
        "print (iter_matches)\n",
        "for hit in iter_matches:\n",
        "    print (hit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqXzlZBWG_dT",
        "outputId": "11d5dc21-9a91-493b-fc5e-a5d7a3ec9ca4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<callable_iterator object at 0x7e5c7b445fc0>\n",
            "<re.Match object; span=(15, 25), match='February 2'>\n",
            "<re.Match object; span=(49, 58), match='14 August'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within each of these is some very salient information, such as the start and end location (inside the span) and the text itself (match). We can use the start and end location to grab the text within the string."
      ],
      "metadata": {
        "id": "4rUAR97PHR7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a date February 2. Another date would be 14 August.\"\n",
        "iter_matches = re.finditer(pattern, text)\n",
        "for hit in iter_matches:\n",
        "    start = hit.start()\n",
        "    end = hit.end()\n",
        "    print (text[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbyZw5nbHTbX",
        "outputId": "d8b1bd73-a307-410a-b963-652b4b8f9066"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "February 2\n",
            "14 August\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.6. How to Use RegEx in spaCy"
      ],
      "metadata": {
        "id": "58BoVK4KHUxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things like dates, times, IP Addresses, etc. that have either consistent or fairly consistent structures are excellent candidates for RegEx. Fortunately, spaCy has easy ways to implement RegEx in three pipes: Matcher, PhraseMatcher, and EntityRuler. One of the major drawbacks to the Matcher and PhraseMatcher, is that they do not align the matches as doc.ents. Because this textbook is about NER and our goal is to store the entities in the doc.ents, we will focus on using RegEx with the EntityRuler. In the next notebook, we will examine other methods."
      ],
      "metadata": {
        "id": "mynZQEa4Hkib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the requisite library\n",
        "import spacy\n",
        "\n",
        "#Sample text\n",
        "text = \"This is a sample number 555-5555.\"\n",
        "\n",
        "#Build upon the spaCy Small Model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "#Create the Ruler and Add it\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "\n",
        "#List of Entities and Patterns (source: https://spacy.io/usage/rule-based-matching)\n",
        "patterns = [\n",
        "                {\"label\": \"PHONE_NUMBER\", \"pattern\": [{\"SHAPE\": \"ddd\"},\n",
        "                {\"ORTH\": \"-\", \"OP\": \"?\"}, {\"SHAPE\": \"dddd\"}]}\n",
        "            ]\n",
        "#add patterns to ruler\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "#create the doc\n",
        "doc = nlp(text)\n",
        "\n",
        "#extract entities\n",
        "for ent in doc.ents:\n",
        "    print (ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpG2Pf-OIGVb",
        "outputId": "88161d9b-72d8-486b-8272-be2a71a99be2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "555-5555 PHONE_NUMBER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r\"((\\d){3}-(\\d){4})\"\n",
        "text = \"This is a sample number 555-5555.\"\n",
        "matches = re.findall(pattern, text)\n",
        "print (matches)"
      ],
      "metadata": {
        "id": "bht0jba7IOAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the requisite library\n",
        "import spacy\n",
        "\n",
        "#Sample text\n",
        "text = \"This is a sample number (555) 555-5555.\"\n",
        "\n",
        "#Build upon the spaCy Small Model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "#Create the Ruler and Add it\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "\n",
        "#List of Entities and Patterns (source: https://spacy.io/usage/rule-based-matching)\n",
        "patterns = [\n",
        "                {\n",
        "                    \"label\": \"PHONE_NUMBER\", \"pattern\": [{\"TEXT\": {\"REGEX\": \"((\\d){3}-(\\d){4})\"}}\n",
        "                                                        ]\n",
        "                }\n",
        "            ]\n",
        "#add patterns to ruler\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "\n",
        "#create the doc\n",
        "doc = nlp(text)\n",
        "\n",
        "#extract entities\n",
        "for ent in doc.ents:\n",
        "    print (ent.text, ent.label_)"
      ],
      "metadata": {
        "id": "Oodk9w-jIVDm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the requisite library\n",
        "import spacy\n",
        "\n",
        "#Sample text\n",
        "text = \"This is a sample number 5555555.\"\n",
        "#Build upon the spaCy Small Model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "#Create the Ruler and Add it\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "\n",
        "#List of Entities and Patterns (source: https://spacy.io/usage/rule-based-matching)\n",
        "patterns = [\n",
        "                {\n",
        "                    \"label\": \"PHONE_NUMBER\", \"pattern\": [{\"TEXT\": {\"REGEX\": \"((\\d){5})\"}}\n",
        "                                                        ]\n",
        "                }\n",
        "            ]\n",
        "#add patterns to ruler\n",
        "ruler.add_patterns(patterns)\n",
        "\n",
        "\n",
        "#create the doc\n",
        "doc = nlp(text)\n",
        "\n",
        "#extract entities\n",
        "for ent in doc.ents:\n",
        "    print (ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM6lT6UfIbI9",
        "outputId": "005d939b-7c80-4f39-a248-b80171dee1d3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5555555 PHONE_NUMBER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.1. Key Concepts in this Notebook¶\n",
        "\n",
        "* Working with Multi-Word Tokens and RegEx in spaCy 3x\n",
        "\n",
        "* RegEx’s Finditer\n",
        "\n",
        "* Spans"
      ],
      "metadata": {
        "id": "lPGVmUQaIm1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.2. Problems with Multi-Word Tokens in spaCy as Entities\n",
        "\n",
        "As we saw in 01.03: Rules-Based NER, we can use spaCy’s Matcher to grab multi-word tokens, or tokens that span multiple tokens. The main problem with this, however, is that these multi-word tokens are not placed into the doc.ents. This means that we cannot access them the same way we would other entities. In this notebook, we will figure out how to solve that problem with a simple workflow:\n",
        "\n",
        "1. Extract Multi-Word Tokens with re.finditer()\n",
        "\n",
        "2. Reconstruct the spans in the spaCy doc\n",
        "\n",
        "3. Give priority to longer spans (Optional)\n",
        "\n",
        "4. Inject the Spans into doc.ents"
      ],
      "metadata": {
        "id": "f4-7vLAbIzK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.3. Extract Multi-Word Tokens"
      ],
      "metadata": {
        "id": "0luiyYKeJIHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to grab the multi-word tokens. In this notebook, we are going to try and grab a multi-word token. In this case, a person whose first name begins with Paul. In the RegEx below, we specify that we are looking for any string that starts with “Paul” and then is followed by a capitalized letter. We then tell it to grab the entire second word until the end of the word."
      ],
      "metadata": {
        "id": "Vmd9P069JVcn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ApwaazkA5rFI"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Paul Newman was an American actor, but Paul Hollywood is a British TV Host. The name Paul is quite common.\""
      ],
      "metadata": {
        "id": "zF-abQq18WZa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r\"Paul [A-Z]\\w+\""
      ],
      "metadata": {
        "id": "Zhnk3CYo8s6x"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches = re.finditer(pattern, text)\n",
        "for match in matches:\n",
        "  print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YctTCjp_81F_",
        "outputId": "65a60428-1852-417c-b0be-fc4493517cf0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 11), match='Paul Newman'>\n",
            "<re.Match object; span=(39, 53), match='Paul Hollywood'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.4. Reconstruct Spans\n",
        "\n"
      ],
      "metadata": {
        "id": "erTOnyXJJYGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import Span"
      ],
      "metadata": {
        "id": "8zFAMTHJ89yj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(text)\n",
        "# print(doc.ents)\n",
        "original_ents = list(doc.ents)\n",
        "mwt_ents = []\n",
        "for match in re.finditer(pattern, doc.text):\n",
        "  start, end = match.span()\n",
        "  span = doc.char_span(start, end)\n",
        "  if span is not None:\n",
        "    mwt_ents.append((span.start, span.end, span.text))\n",
        "\n",
        "for ent in mwt_ents:\n",
        "  start, end, name = ent\n",
        "  per_ent = Span(doc, start, end, label=\"PERSON\")\n",
        "  original_ents.append(per_ent)\n",
        "\n",
        "doc.ents = original_ents\n",
        "print(doc.ents)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXKkTX0_89iU",
        "outputId": "73f1f753-bdd7-4d30-c701-e219d700393a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Paul Newman, Paul Hollywood)\n",
            "Paul Newman PERSON\n",
            "Paul Hollywood PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mwt_ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKSu_rS28pCP",
        "outputId": "606bd458-45d4-4e62-ab93-0d406af666cc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 2, 'Paul Newman'), (8, 10, 'Paul Hollywood')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.5. Inject the Spans into the doc.ents"
      ],
      "metadata": {
        "id": "m1kUaq_3LbRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.language import Language\n",
        "\n",
        "@Language.component(\"paul_ner\")\n",
        "def paul_ner(doc):\n",
        "  pattern = r\"Paul [A-Z]\\w+\"\n",
        "  original_ents = list(doc.ents)\n",
        "  mwt_ents = []\n",
        "  for match in re.finditer(pattern, doc.text):\n",
        "    start, end = match.span()\n",
        "    span = doc.char_span(start, end)\n",
        "    if span is not None:\n",
        "      mwt_ents.append((span.start, span.end, span.text))\n",
        "\n",
        "  for ent in mwt_ents:\n",
        "    start, end, name = ent\n",
        "    per_ent = Span(doc, start, end, label=\"PERSON\")\n",
        "    original_ents.append(per_ent)\n",
        "\n",
        "  doc.ents = original_ents\n",
        "  return (doc)"
      ],
      "metadata": {
        "id": "pZQ6smny-F0y"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2 = spacy.blank(\"en\")\n",
        "nlp2.add_pipe(\"paul_ner\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "11frpVptAPck",
        "outputId": "67571667-6706-46b2-e7c0-43aa5c6c6d3c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.paul_ner(doc)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>paul_ner</b><br/>def paul_ner(doc)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-38-844366819609&gt;</a>&lt;no docstring&gt;</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 = nlp2(text)\n",
        "print(doc2.ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqV3i0niAeJq",
        "outputId": "5a0f6a93-2da4-48e6-e17b-bf5f72ff1911"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Paul Newman, Paul Hollywood)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.language import Language\n",
        "from spacy.util import filter_spans\n",
        "\n",
        "@Language.component(\"cinema_ner\")\n",
        "def cinema_ner(doc):\n",
        "  pattern = r\"Hollywood\"\n",
        "  original_ents = list(doc.ents)\n",
        "  mwt_ents = []\n",
        "  for match in re.finditer(pattern, doc.text):\n",
        "    start, end = match.span()\n",
        "    span = doc.char_span(start, end)\n",
        "    if span is not None:\n",
        "      mwt_ents.append((span.start, span.end, span.text))\n",
        "\n",
        "  for ent in mwt_ents:\n",
        "    start, end, name = ent\n",
        "    per_ent = Span(doc, start, end, label=\"CINEMA\")\n",
        "    original_ents.append(per_ent)\n",
        "\n",
        "  filtered = filter_spans(original_ents)\n",
        "  doc.ents = filtered\n",
        "  return (doc)"
      ],
      "metadata": {
        "id": "7fiOq4giAkXM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp3 = spacy.load(\"en_core_web_sm\")\n",
        "nlp3.add_pipe(\"cinema_ner\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "yb2STmRTA1At",
        "outputId": "cd7ad122-cade-4f87-ceeb-918062d9a70e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.cinema_ner(doc)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>cinema_ner</b><br/>def cinema_ner(doc)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-44-b13a1c1ffa75&gt;</a>&lt;no docstring&gt;</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3 = nlp3(text)\n",
        "for ent in doc3.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZtZ3WCGBNrR",
        "outputId": "a0cdc828-cce5-4748-ef59-23185a59f426"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paul Newman PERSON\n",
            "American NORP\n",
            "Paul Hollywood PERSON\n",
            "British NORP\n",
            "Paul PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8yc9zVgBUMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}